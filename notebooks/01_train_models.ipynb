{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training mdoels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using helpers from: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/notebooks/src\n",
      "utils.utils   -> ModuleSpec(name='utils.utils', loader=<_frozen_importlib_external.SourceFileLoader object at 0x105446d50>, origin='/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/utils/utils.py')\n",
      "modules.memory-> ModuleSpec(name='modules.memory', loader=<_frozen_importlib_external.SourceFileLoader object at 0x10545f110>, origin='/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/modules/memory.py')\n",
      "REPO_ROOT        : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\n",
      "PKG_DIR          : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/time_to_explain\n",
      "RESOURCES_DIR    : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources\n",
      "PROCESSED_DATA_DIR: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/datasets/processed\n",
      "MODELS_ROOT      : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models\n"
     ]
    }
   ],
   "source": [
    "# Find and add `notebooks/src` to sys.path, no matter where the notebook lives.\n",
    "from pathlib import Path\n",
    "import sys, importlib\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def _add_notebooks_src_to_path():\n",
    "    here = Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        candidate = p / \"notebooks\" / \"src\"\n",
    "        if candidate.is_dir():\n",
    "            if str(candidate) not in sys.path:\n",
    "                sys.path.insert(0, str(candidate))\n",
    "            return candidate\n",
    "    raise FileNotFoundError(\"Could not find 'notebooks/src' from current working directory.\")\n",
    "\n",
    "print(\"Using helpers from:\", _add_notebooks_src_to_path())\n",
    "\n",
    "from constants import (\n",
    "    REPO_ROOT, PKG_DIR, RESOURCES_DIR, PROCESSED_DATA_DIR, MODELS_ROOT, TGN_SUBMODULE_ROOT, ensure_repo_importable, get_last_checkpoint\n",
    ")\n",
    "ensure_repo_importable()\n",
    "from device import pick_device\n",
    "\n",
    "for p in (str(TGN_SUBMODULE_ROOT), str(REPO_ROOT), str(PKG_DIR)):\n",
    "    if p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "# 2) If your notebook already imported `utils`, remove it to avoid collision\n",
    "if \"utils\" in sys.modules:\n",
    "    del sys.modules[\"utils\"]\n",
    "\n",
    "importlib.invalidate_caches()\n",
    "\n",
    "# 4) (Optional) sanity check that TGN's local packages resolve\n",
    "import importlib.util as iu\n",
    "print(\"utils.utils   ->\", iu.find_spec(\"utils.utils\"))\n",
    "print(\"modules.memory->\", iu.find_spec(\"modules.memory\"))\n",
    "\n",
    "# 5) Now this import should work without the previous error\n",
    "from time_to_explain.models.wrapper import (\n",
    "    create_dataset, create_tgn_wrapper, create_wrapper, create_tgat_wrapper\n",
    ")\n",
    "\n",
    "print(\"REPO_ROOT        :\", REPO_ROOT)\n",
    "print(\"PKG_DIR          :\", PKG_DIR)\n",
    "print(\"RESOURCES_DIR    :\", RESOURCES_DIR)\n",
    "print(\"PROCESSED_DATA_DIR:\", PROCESSED_DATA_DIR)\n",
    "print(\"MODELS_ROOT      :\", MODELS_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "MODEL_TYPE = \"TGAT\"\n",
    "DATASET_NAME = \"wikipedia\"\n",
    "BIPARTITE = True\n",
    "DIRECTED = False\n",
    "EPOCHS = 30\n",
    "\n",
    "MODEL_PATH = MODELS_ROOT / DATASET_NAME\n",
    "CHECKPOINT_PATH = MODEL_PATH / 'checkpoints/'\n",
    "if not os.path.exists(CHECKPOINT_PATH):\n",
    "    os.mkdir(CHECKPOINT_PATH)\n",
    "LAST_CHECKPOINT = get_last_checkpoint(CHECKPOINT_PATH,MODEL_TYPE, DATASET_NAME)    \n",
    "DEVICE = pick_device(\"auto\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tgnn_variables(\n",
    "    *,\n",
    "    dataset_name: str,              \n",
    "    model_type: str = \"TGN\",        # \"TGN\" or \"TGAT\"\n",
    "    epochs: int = 30,\n",
    "    directed: bool = False,\n",
    "    bipartite: bool = False,\n",
    "    device: str = \"auto\",           # \"auto\" | \"cpu\" | \"cuda\" | \"mps\"\n",
    "    cuda: bool = True,              # legacy flag supported by your device selector\n",
    "    update_memory_at_start: bool = False,\n",
    "    model_dir = MODEL_PATH,\n",
    "    checkpoint_path: str | None = None,  # resume/init checkpoint (optional)\n",
    "    last_checkpoint: str | None = None, \n",
    "    out_root: str | Path | None = None,  # defaults to MODELS_ROOT\n",
    "):\n",
    "    \"\"\"\n",
    "    Train T-GNN/TGAT using only Python variables (no argparse).\n",
    "\n",
    "    Saves:\n",
    "      <out_root>/<dataset_name>/checkpoints/\n",
    "      <out_root>/<dataset_name>/results.pkl\n",
    "\n",
    "    Returns:\n",
    "      wrapper (so you can evaluate/inspect in the notebook)\n",
    "      model_dir (Path to the run's artifacts)\n",
    "      results_path (Path to results.pkl)\n",
    "    \"\"\"\n",
    "    # ---- Resolve paths\n",
    "    dataset_dir = Path(PROCESSED_DATA_DIR) / dataset_name\n",
    "    if not dataset_dir.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Processed dataset directory not found: {dataset_dir}\\n\"\n",
    "            f\"Set PROCESSED_DATA_DIR in constants.py or fix dataset_name.\"\n",
    "        )\n",
    "\n",
    "    # ---- Build wrapper (variable-based API, no parser)\n",
    "    wrapper = create_wrapper(\n",
    "        model_type=model_type,\n",
    "        dataset_dir=str(dataset_dir),\n",
    "        directed=directed,\n",
    "        bipartite=bipartite,\n",
    "        device=device,\n",
    "        update_memory_at_start=update_memory_at_start,\n",
    "        checkpoint_path=last_checkpoint,\n",
    "    )\n",
    "\n",
    "    # ---- Train\n",
    "    results_path = model_dir / \"results.pkl\"\n",
    "\n",
    "    print(f\"Training {model_type} on '{dataset_name}'\"\n",
    "          f\"{' (bipartite)' if bipartite else ''}\"\n",
    "          f\"{' (directed)' if directed else ''} …\")\n",
    "    print(\"repo root     :\", REPO_ROOT)\n",
    "    print(\"dataset dir   :\", dataset_dir)\n",
    "    print(\"model out dir :\", model_dir)\n",
    "    print(\"epochs        :\", epochs)\n",
    "    print(\"device        :\", device, \"(cuda flag:\", cuda, \")\")\n",
    "    if checkpoint_path:\n",
    "        print(\"resume from   :\", checkpoint_path)\n",
    "\n",
    "    wrapper.train_model(\n",
    "        epochs,\n",
    "        checkpoint_path=str(checkpoint_path),\n",
    "        results_path=str(results_path),\n",
    "    )\n",
    "\n",
    "    return wrapper, model_dir, results_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TGATWrapper...\n",
      "Training TGAT on 'wikipedia' (bipartite) …\n",
      "repo root     : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\n",
      "dataset dir   : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/datasets/processed/wikipedia\n",
      "model out dir : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/wikipedia\n",
      "epochs        : 30\n",
      "device        : mps (cuda flag: True )\n",
      "resume from   : /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/wikipedia/checkpoints\n",
      "The dataset has 157474 interactions, involving 9227 different nodes\n",
      "The training dataset has 79750 interactions, involving 5992 different nodes\n",
      "The validation dataset has 23621 interactions, involving 3256 different nodes\n",
      "The test dataset has 23621 interactions, involving 3564 different nodes\n",
      "The new node validation dataset has 11738 interactions, involving 2115 different nodes\n",
      "The new node test dataset has 11756 interactions, involving 2483 different nodes\n",
      "922 nodes were used for the inductive testing, i.e. are never seen during training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TGNNWrapper:num of training instances: 79750\n",
      "INFO:TGNNWrapper:num of batches per epoch: 2493\n",
      "INFO:TGNNWrapper:start 0 epoch\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf4773d6bd8461d99be09a567c9a558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/2493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'TGATWrapper' object has no attribute 'full_ngh_finder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wrapper, model_dir, results_path \u001b[38;5;241m=\u001b[39m train_tgnn_variables(\n\u001b[1;32m      2\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mDATASET_NAME,\n\u001b[1;32m      3\u001b[0m     model_type\u001b[38;5;241m=\u001b[39mMODEL_TYPE,\n\u001b[1;32m      4\u001b[0m     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[1;32m      5\u001b[0m     directed\u001b[38;5;241m=\u001b[39mDIRECTED,\n\u001b[1;32m      6\u001b[0m     bipartite\u001b[38;5;241m=\u001b[39mBIPARTITE,\n\u001b[1;32m      7\u001b[0m     device\u001b[38;5;241m=\u001b[39mDEVICE,   \u001b[38;5;66;03m# or \"cuda\"/\"cpu\"/\"mps\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     model_dir\u001b[38;5;241m=\u001b[39mMODEL_PATH,\n\u001b[1;32m      9\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39mCHECKPOINT_PATH,  \u001b[38;5;66;03m# optional resume\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     last_checkpoint\u001b[38;5;241m=\u001b[39mLAST_CHECKPOINT,\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m#out_root=\"/custom/output/root\",      # defaults to MODELS_ROOT\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n",
      "Cell \u001b[0;32mIn[3], line 61\u001b[0m, in \u001b[0;36mtrain_tgnn_variables\u001b[0;34m(dataset_name, model_type, epochs, directed, bipartite, device, cuda, update_memory_at_start, model_dir, checkpoint_path, last_checkpoint, out_root)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume from   :\u001b[39m\u001b[38;5;124m\"\u001b[39m, checkpoint_path)\n\u001b[0;32m---> 61\u001b[0m wrapper\u001b[38;5;241m.\u001b[39mtrain_model(\n\u001b[1;32m     62\u001b[0m     epochs,\n\u001b[1;32m     63\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(checkpoint_path),\n\u001b[1;32m     64\u001b[0m     results_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(results_path),\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper, model_dir, results_path\n",
      "File \u001b[0;32m~/Documents/CodingProjects/master_thesis/time_to_explain/time_to_explain/models/adapter/tgn.py:337\u001b[0m, in \u001b[0;36mTGNWrapper.train_model\u001b[0;34m(self, epochs, learning_rate, early_stop_patience, checkpoint_path, model_path, results_path)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_memory:\n\u001b[1;32m    334\u001b[0m     train_memory_backup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mbackup_memory()\n\u001b[1;32m    336\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m eval_edge_prediction(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m--> 337\u001b[0m                        neighbor_finder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_ngh_finder,\n\u001b[1;32m    338\u001b[0m                        data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_data,\n\u001b[1;32m    339\u001b[0m                        negative_edge_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_edge_sampler,\n\u001b[1;32m    340\u001b[0m                        batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    341\u001b[0m                        device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    343\u001b[0m val_ap, val_auc, val_acc \u001b[38;5;241m=\u001b[39m _unpack_metrics(val_metrics)\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_memory:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TGATWrapper' object has no attribute 'full_ngh_finder'"
     ]
    }
   ],
   "source": [
    "wrapper, model_dir, results_path = train_tgnn_variables(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    model_type=MODEL_TYPE,\n",
    "    epochs=EPOCHS,\n",
    "    directed=DIRECTED,\n",
    "    bipartite=BIPARTITE,\n",
    "    device=DEVICE,   # or \"cuda\"/\"cpu\"/\"mps\"\n",
    "    model_dir=MODEL_PATH,\n",
    "    checkpoint_path=CHECKPOINT_PATH,  # optional resume\n",
    "    last_checkpoint=LAST_CHECKPOINT,\n",
    "    #out_root=\"/custom/output/root\",      # defaults to MODELS_ROOT\n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
