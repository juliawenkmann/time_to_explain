{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f528aa",
   "metadata": {},
   "source": [
    "# Training Launcher (TGN / TGAT)\n",
    "\n",
    "This block adds a simple switch to run **TGN** or **TGAT** training from the notebook.\n",
    "\n",
    "- **TGN**: calls your script  \n",
    "  `/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/train_self_supervised.py`  \n",
    "  with the exact args you gave: `--use_memory --prefix tgn-attn --n_runs 10`.\n",
    "\n",
    "- **TGAT**: included as a template. Adjust the `TGAT_SCRIPT` path and arguments to match your repo (see the code cell for details).\n",
    "\n",
    "> Tip: set `DRY_RUN=True` first to confirm the command, then set it to `False` to actually launch training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad1145db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded.\n",
      "PROJECT_ROOT: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\n",
      "MODEL_TYPE: TGN\n",
      "DATA_TYPE: wikipedia\n",
      "TGN script: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/train_self_supervised.py\n",
      "TGAT script: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgat/train_supervised.py\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys, subprocess, shlex\n",
    "from datetime import datetime\n",
    "\n",
    "# === User configuration ===\n",
    "MODEL_TYPE = \"TGN\"   # \"TGN\" or \"TGAT\"\n",
    "DATA_TYPE = \"wikipedia\"\n",
    "DRY_RUN = False      # True -> print command only, False -> actually run it\n",
    "PYTHON_BIN = \"python\"  # or an absolute path to your env's python\n",
    "\n",
    "# Your repository root (as on your machine)\n",
    "PROJECT_ROOT = Path(\"/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\").resolve()\n",
    "\n",
    "# Optional: restrict GPUs (set None to leave unchanged)\n",
    "CUDA_VISIBLE_DEVICES = None  # e.g., \"0\" or \"0,1\"\n",
    "\n",
    "# ---- TGN config (exactly as requested) ----\n",
    "TGN_SCRIPT = PROJECT_ROOT / \"submodules\" / \"models\" / \"tgn\" / \"train_self_supervised.py\"\n",
    "TGN_ARGS = [\"--data\", DATA_TYPE, \"--use_memory\", \"--prefix\", \"tgn-attn\", \"--n_runs\", \"10\"]\n",
    "\n",
    "# ---- TGAT config (TEMPLATE — update to your actual script/args) ----\n",
    "# Common TGAT repos expose a training entry point like train_supervised.py or main.py.\n",
    "# Adjust TGAT_SCRIPT and TGAT_ARGS to match your setup.\n",
    "TGAT_SCRIPT = PROJECT_ROOT / \"submodules\" / \"models\" / \"tgat\" / \"train_supervised.py\"  # <-- change if different\n",
    "TGAT_ARGS = [\"--prefix\", \"tgat-attn\", \"--n_runs\", \"10\"]  # <-- add/remove flags as your script expects\n",
    "\n",
    "# === Derived / utility ===\n",
    "def build_cmd(python_bin, script_path, extra_args):\n",
    "    if not script_path.exists():\n",
    "        raise FileNotFoundError(f\"Training script not found: {script_path}\")\n",
    "    return [python_bin, str(script_path), *extra_args]\n",
    "\n",
    "def run_cmd(cmd, env=None):\n",
    "    print(\"$\", \" \".join(shlex.quote(c) for c in cmd))\n",
    "    if DRY_RUN:\n",
    "        print(\"[DRY_RUN] Skipping execution.\")\n",
    "        return 0\n",
    "    proc = subprocess.run(cmd, env=env, check=False)\n",
    "    if proc.returncode != 0:\n",
    "        print(f\"[ERROR] process exited with code {proc.returncode}\")\n",
    "    return proc.returncode\n",
    "\n",
    "def prepare_env():\n",
    "    env = os.environ.copy()\n",
    "    if CUDA_VISIBLE_DEVICES is not None:\n",
    "        env[\"CUDA_VISIBLE_DEVICES\"] = str(CUDA_VISIBLE_DEVICES)\n",
    "        print(\"Set CUDA_VISIBLE_DEVICES =\", env[\"CUDA_VISIBLE_DEVICES\"])\n",
    "    # Ensure the repo root is on PYTHONPATH for intra-repo imports\n",
    "    env[\"PYTHONPATH\"] = str(PROJECT_ROOT) + os.pathsep + env.get(\"PYTHONPATH\", \"\")\n",
    "    return env\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MODEL_TYPE:\", MODEL_TYPE)\n",
    "print(\"DATA_TYPE:\", DATA_TYPE)\n",
    "print(\"TGN script:\", TGN_SCRIPT)\n",
    "print(\"TGAT script:\", TGAT_SCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928f0916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ python /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/train_self_supervised.py --data wikipedia --use_memory --prefix tgn-attn --n_runs 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(data='wikipedia', bs=200, prefix='tgn-attn', n_degree=10, n_head=2, n_epoch=50, n_layer=1, lr=0.0001, patience=5, n_runs=10, drop_out=0.1, gpu=0, node_dim=100, time_dim=100, backprop_every=1, use_memory=True, embedding_module='graph_attention', message_function='identity', memory_updater='gru', aggregator='last', memory_update_at_end=False, message_dim=100, memory_dim=172, different_new_nodes=False, uniform=False, randomize_features=False, use_destination_embedding_in_message=False, use_source_embedding_in_message=False, dyrep=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 157474 interactions, involving 9227 different nodes\n",
      "The training dataset has 79202 interactions, involving 5904 different nodes\n",
      "The validation dataset has 23621 interactions, involving 3256 different nodes\n",
      "The test dataset has 23621 interactions, involving 3564 different nodes\n",
      "The new node validation dataset has 11742 interactions, involving 2134 different nodes\n",
      "The new node test dataset has 11765 interactions, involving 2482 different nodes\n",
      "922 nodes were used for the inductive testing, i.e. are never seen during training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:num of training instances: 79202\n",
      "INFO:root:num of batches per epoch: 397\n",
      "INFO:root:start 0 epoch\n",
      "INFO:root:epoch: 0 took 128.07s\n",
      "INFO:root:Epoch mean loss: 0.891759562402288\n",
      "INFO:root:val auc: 0.8724800994207206, new node val auc: 0.8589361676204278\n",
      "INFO:root:val ap: 0.8652861989403586, new node val ap: 0.8524048537663556\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/train_self_supervised.py\", line 302, in <module>\n",
      "    torch.save(tgn.state_dict(), get_checkpoint_path(epoch))\n",
      "  File \"/Users/juliawenkmann/miniconda3/envs/graphs/lib/python3.11/site-packages/torch/serialization.py\", line 849, in save\n",
      "    with _open_zipfile_writer(f) as opened_zipfile:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juliawenkmann/miniconda3/envs/graphs/lib/python3.11/site-packages/torch/serialization.py\", line 716, in _open_zipfile_writer\n",
      "    return container(name_or_buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/juliawenkmann/miniconda3/envs/graphs/lib/python3.11/site-packages/torch/serialization.py\", line 687, in __init__\n",
      "    super().__init__(torch._C.PyTorchFileWriter(self.name))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: Parent directory None/saved_checkpoints does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] process exited with code 1\n",
      "[TGN] Training failed — see output above.\n"
     ]
    }
   ],
   "source": [
    "# --- Launch training based on MODEL_TYPE ---\n",
    "env = prepare_env()\n",
    "\n",
    "if MODEL_TYPE.upper() == \"TGN\":\n",
    "    cmd = build_cmd(PYTHON_BIN, TGN_SCRIPT, TGN_ARGS)\n",
    "    code = run_cmd(cmd, env=env)\n",
    "    if code == 0:\n",
    "        print(\"[TGN] Training completed (or started successfully).\")\n",
    "    else:\n",
    "        print(\"[TGN] Training failed — see output above.\")\n",
    "\n",
    "elif MODEL_TYPE.upper() == \"TGAT\":\n",
    "    try:\n",
    "        cmd = build_cmd(PYTHON_BIN, TGAT_SCRIPT, TGAT_ARGS)\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(\n",
    "            f\"{e}\\n\\n\"\n",
    "            \"TGAT template provided — please set TGAT_SCRIPT to your actual training entry point \"\n",
    "            \"and adjust TGAT_ARGS to match your script.\"\n",
    "        )\n",
    "    code = run_cmd(cmd, env=env)\n",
    "    if code == 0:\n",
    "        print(\"[TGAT] Training completed (or started successfully).\")\n",
    "    else:\n",
    "        print(\"[TGAT] Training failed — see output above.\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"MODEL_TYPE must be 'TGN' or 'TGAT'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
