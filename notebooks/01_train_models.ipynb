{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f528aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook config: seed=42, device=mps\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _bootstrap_repo_root(start: Path | None = None) -> Path:\n",
    "    here = (start or Path.cwd()).resolve()\n",
    "    for candidate in (here, *here.parents):\n",
    "        if (candidate / \"time_to_explain\").is_dir():\n",
    "            return candidate\n",
    "    raise RuntimeError(\n",
    "        f\"Could not locate the repository root from {here}. \"\n",
    "        \"Set PROJECT_ROOT manually if your layout is unusual.\"\n",
    "    )\n",
    "\n",
    "\n",
    "PROJECT_ROOT = _bootstrap_repo_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from time_to_explain.utils.device import pick_device\n",
    "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"notebooks\" / \"global.json\"\n",
    "NOTEBOOK_CFG = json.loads(CONFIG_PATH.read_text(encoding=\"utf-8\")) if CONFIG_PATH.exists() else {}\n",
    "SEED = int(NOTEBOOK_CFG.get(\"seed\", 42))\n",
    "DEVICE = pick_device(NOTEBOOK_CFG.get(\"device\", \"auto\"))\n",
    "print(f\"Notebook config: seed={SEED}, device={DEVICE}\")\n",
    "\n",
    "from time_to_explain.models.utils import (\n",
    "    build_cmd,\n",
    "    ensure_tempme_processed,\n",
    "    ensure_workdir,\n",
    "    export_trained_models,\n",
    "    prepare_env,\n",
    "    run_cmd,\n",
    ")\n",
    "from time_to_explain.utils.cli import (\n",
    "    args_dict_to_list,\n",
    "    normalize_datasets,\n",
    "    resolve_path,\n",
    "    slugify,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"wikipedia\" #'triadic_closure' #\"stick_figure\"  # change to \"nicolaus\", etc.\n",
    "MODEL_TYPE = \"tgn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded from: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/configs/models/train_tgn_wikipedia.json\n",
      "PROJECT_ROOT: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\n",
      "MODEL_TYPE: TGN\n",
      "DATASETS: ['wikipedia']\n",
      "Artifacts root: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/runs\n",
      "Sample run directory: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/runs/tgn_wikipedia\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = Path(f\"configs/models/train_{MODEL_TYPE}_{DATASET_NAME}.json\")\n",
    "\n",
    "CONFIG_PATH = resolve_path(str(CONFIG_PATH), root=PROJECT_ROOT)\n",
    "if CONFIG_PATH is None or not CONFIG_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Config not found: {CONFIG_PATH}\")\n",
    "CONFIG = json.loads(CONFIG_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "MODEL_TYPE = str(CONFIG.get(\"model_type\", \"TGN\")).upper()\n",
    "DATASET_LIST = normalize_datasets(CONFIG.get(\"datasets\", []))\n",
    "PYTHON_BIN = str(CONFIG.get(\"python_bin\", \"python\"))\n",
    "DRY_RUN = bool(CONFIG.get(\"dry_run\", False))\n",
    "CUDA_VISIBLE_DEVICES = CONFIG.get(\"cuda_visible_devices\")\n",
    "\n",
    "MODEL_SPECS = {str(k).upper(): v for k, v in (CONFIG.get(\"models\") or {}).items()}\n",
    "if MODEL_TYPE not in MODEL_SPECS:\n",
    "    raise KeyError(f\"Model spec for {MODEL_TYPE} missing in {CONFIG_PATH}\")\n",
    "\n",
    "RESOURCES_MODELS = resolve_path(CONFIG.get(\"resources_models_dir\", \"resources/models\"), root=PROJECT_ROOT)\n",
    "RUNS_ROOT = resolve_path(CONFIG.get(\"runs_root\", \"resources/models/runs\"), root=PROJECT_ROOT)\n",
    "RESOURCES_DATASETS = resolve_path(CONFIG.get(\"resources_datasets_dir\", \"resources/datasets/processed\"), root=PROJECT_ROOT)\n",
    "\n",
    "DEFAULT_WORKDIR = RUNS_ROOT / f\"{slugify(MODEL_TYPE)}_{slugify(DATASET_LIST[0])}\"\n",
    "\n",
    "TGN_SPEC = MODEL_SPECS.get(\"TGN\", {})\n",
    "TGAT_SPEC = MODEL_SPECS.get(\"TGAT\", {})\n",
    "GRAPHMIXER_SPEC = MODEL_SPECS.get(\"GRAPHMIXER\", {})\n",
    "\n",
    "TGN_SCRIPT = resolve_path(TGN_SPEC.get(\"script\"), root=PROJECT_ROOT)\n",
    "TGAT_SCRIPT = resolve_path(TGAT_SPEC.get(\"script\"), root=PROJECT_ROOT)\n",
    "GRAPHMIXER_SCRIPT = resolve_path(GRAPHMIXER_SPEC.get(\"script\"), root=PROJECT_ROOT)\n",
    "GRAPHMIXER_PROCESSED_DIR = resolve_path(GRAPHMIXER_SPEC.get(\"processed_dir\"), root=PROJECT_ROOT)\n",
    "GRAPHMIXER_PARAMS_DIR = resolve_path(GRAPHMIXER_SPEC.get(\"params_dir\"), root=PROJECT_ROOT)\n",
    "\n",
    "def get_tgn_args(dataset: str) -> list[str]:\n",
    "    return args_dict_to_list(TGN_SPEC.get(\"args\", {}), dataset)\n",
    "\n",
    "def get_tgat_args(dataset: str) -> list[str]:\n",
    "    return args_dict_to_list(TGAT_SPEC.get(\"args\", {}), dataset)\n",
    "\n",
    "def get_graphmixer_args(dataset: str) -> list[str]:\n",
    "    return args_dict_to_list(GRAPHMIXER_SPEC.get(\"args\", {}), dataset)\n",
    "\n",
    "print(\"Configuration loaded from:\", CONFIG_PATH)\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MODEL_TYPE:\", MODEL_TYPE)\n",
    "print(\"DATASETS:\", DATASET_LIST)\n",
    "print(\"Artifacts root:\", RUNS_ROOT)\n",
    "print(\"Sample run directory:\", DEFAULT_WORKDIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1145db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Launching TGN on wikipedia ===\n",
      "Artifacts will be stored under: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/runs/tgn_wikipedia\n",
      "$ (cwd=/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/models/runs/tgn_wikipedia) python /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/models/tgn/train_self_supervised.py --data wikipedia --use_memory --prefix tgn-attn --n_runs 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(data='wikipedia', bs=200, prefix='tgn-attn', n_degree=10, n_head=2, n_epoch=50, n_layer=1, lr=0.0001, patience=5, n_runs=10, drop_out=0.1, gpu=0, node_dim=100, time_dim=100, backprop_every=1, use_memory=True, embedding_module='graph_attention', message_function='identity', memory_updater='gru', aggregator='last', memory_update_at_end=False, message_dim=100, memory_dim=172, different_new_nodes=False, uniform=False, randomize_features=False, use_destination_embedding_in_message=False, use_source_embedding_in_message=False, dyrep=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain\n",
      "The dataset has 157474 interactions, involving 9227 different nodes\n",
      "The training dataset has 79202 interactions, involving 5904 different nodes\n",
      "The validation dataset has 23621 interactions, involving 3256 different nodes\n",
      "The test dataset has 23621 interactions, involving 3564 different nodes\n",
      "The new node validation dataset has 11742 interactions, involving 2134 different nodes\n",
      "The new node test dataset has 11765 interactions, involving 2482 different nodes\n",
      "922 nodes were used for the inductive testing, i.e. are never seen during training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:num of training instances: 79202\n",
      "INFO:root:num of batches per epoch: 397\n",
      "INFO:root:start 0 epoch\n"
     ]
    }
   ],
   "source": [
    "# --- Launch training for each dataset ---\n",
    "import shutil\n",
    "\n",
    "\n",
    "def ensure_tgn_processed(dataset: str, processed_root: Path) -> Path:\n",
    "    \"\"\"Create legacy per-dataset folder for TGN if the repo uses a flat layout.\"\"\"\n",
    "    legacy_dir = processed_root / dataset\n",
    "    legacy_files = [\n",
    "        legacy_dir / f\"ml_{dataset}{suffix}\" for suffix in (\".csv\", \".npy\", \"_node.npy\")\n",
    "    ]\n",
    "    if all(p.exists() for p in legacy_files):\n",
    "        return legacy_dir\n",
    "\n",
    "    flat_files = [\n",
    "        processed_root / f\"ml_{dataset}{suffix}\" for suffix in (\".csv\", \".npy\", \"_node.npy\")\n",
    "    ]\n",
    "    missing = [p for p in flat_files if not p.exists()]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(\n",
    "            \"Missing processed files: \" + \", \".join(str(p) for p in missing)\n",
    "        )\n",
    "\n",
    "    legacy_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for src in flat_files:\n",
    "        dst = legacy_dir / src.name\n",
    "        if dst.exists() or dst.is_symlink():\n",
    "            continue\n",
    "        try:\n",
    "            dst.symlink_to(src)\n",
    "        except Exception:\n",
    "            shutil.copy2(src, dst)\n",
    "    return legacy_dir\n",
    "\n",
    "\n",
    "env = prepare_env(project_root=PROJECT_ROOT, cuda_visible_devices=CUDA_VISIBLE_DEVICES)\n",
    "\n",
    "for dataset in DATASET_LIST:\n",
    "    workdir = ensure_workdir(RUNS_ROOT, MODEL_TYPE, dataset)\n",
    "    print(\"=== Launching\", MODEL_TYPE.upper(), \"on\", dataset, \"===\")\n",
    "    print(\"Artifacts will be stored under:\", workdir)\n",
    "\n",
    "    if MODEL_TYPE.upper() == \"TGN\":\n",
    "        ensure_tgn_processed(dataset, RESOURCES_DATASETS)\n",
    "        cmd = build_cmd(PYTHON_BIN, TGN_SCRIPT, get_tgn_args(dataset))\n",
    "        code = run_cmd(cmd, env=env, workdir=workdir, dry_run=DRY_RUN)\n",
    "        if code == 0:\n",
    "            export_trained_models(MODEL_TYPE, dataset, workdir, RESOURCES_MODELS)\n",
    "            print(\"[TGN] Training completed (or started successfully) for\", dataset)\n",
    "        else:\n",
    "            print(\"[TGN] Training failed for\", dataset, \"- see output above.\")\n",
    "\n",
    "    elif MODEL_TYPE.upper() == \"TGAT\":\n",
    "        try:\n",
    "            cmd = build_cmd(PYTHON_BIN, TGAT_SCRIPT, get_tgat_args(dataset))\n",
    "        except FileNotFoundError as exc:\n",
    "            raise FileNotFoundError(\n",
    "                f\"{exc} Update configs/models to point to your TGAT training script.\"\n",
    "            )\n",
    "        code = run_cmd(cmd, env=env, workdir=workdir, dry_run=DRY_RUN)\n",
    "        if code == 0:\n",
    "            export_trained_models(MODEL_TYPE, dataset, workdir, RESOURCES_MODELS)\n",
    "            print(\"[TGAT] Training completed (or started successfully) for\", dataset)\n",
    "        else:\n",
    "            print(\"[TGAT] Training failed for\", dataset, \"- see output above.\")\n",
    "\n",
    "    elif MODEL_TYPE.upper() == \"GRAPHMIXER\":\n",
    "        if GRAPHMIXER_PROCESSED_DIR is None:\n",
    "            raise ValueError(\"GRAPHMIXER processed_dir missing in config.\")\n",
    "        ensure_tempme_processed(\n",
    "            dataset,\n",
    "            processed_dir=GRAPHMIXER_PROCESSED_DIR,\n",
    "            resources_datasets=RESOURCES_DATASETS,\n",
    "        )\n",
    "        if not GRAPHMIXER_SCRIPT or not GRAPHMIXER_SCRIPT.exists():\n",
    "            raise FileNotFoundError(f\"GraphMixer training script not found: {GRAPHMIXER_SCRIPT}\")\n",
    "        cmd = build_cmd(PYTHON_BIN, GRAPHMIXER_SCRIPT, get_graphmixer_args(dataset))\n",
    "        code = run_cmd(cmd, env=env, workdir=GRAPHMIXER_SCRIPT.parent, dry_run=DRY_RUN)\n",
    "        if code == 0:\n",
    "            exported = []\n",
    "            if GRAPHMIXER_PARAMS_DIR and GRAPHMIXER_PARAMS_DIR.exists():\n",
    "                dest_dir = RESOURCES_MODELS / slugify(dataset) / \"graphmixer\"\n",
    "                dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "                for src_file in sorted(GRAPHMIXER_PARAMS_DIR.glob(f\"graphmixer_{slugify(dataset)}*.pt\")):\n",
    "                    dest_path = dest_dir / src_file.name\n",
    "                    dest_path.write_bytes(src_file.read_bytes())\n",
    "                    exported.append(dest_path)\n",
    "                if not exported:\n",
    "                    for src_file in sorted(GRAPHMIXER_PARAMS_DIR.glob(\"graphmixer_*.pt\")):\n",
    "                        dest_path = dest_dir / src_file.name\n",
    "                        dest_path.write_bytes(src_file.read_bytes())\n",
    "                        exported.append(dest_path)\n",
    "            if exported:\n",
    "                print(\"[GraphMixer] Exported:\")\n",
    "                for p in exported:\n",
    "                    print(\" -\", p)\n",
    "            else:\n",
    "                print(\"[GraphMixer] No checkpoints found under\", GRAPHMIXER_PARAMS_DIR)\n",
    "            print(\"[GraphMixer] Training completed (or started successfully) for\", dataset)\n",
    "        else:\n",
    "            print(\"[GraphMixer] Training failed for\", dataset)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"MODEL_TYPE must be 'TGN' or 'TGAT' or 'GRAPHMIXER'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba91cbd-365a-432f-b5ed-4ee86a507808",
   "metadata": {},
   "source": [
    "### TempME pretraining (run once, outside evaluation)\n",
    "Pre-train the TempME base model + explainer here so evaluation notebooks can set `train_if_missing=False` and avoid training inside the explainer pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8702685-8945-4fb2-9124-065772bc23e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TempME] Base checkpoint exists: /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/explainer/tempme/params/tgnn/tgn_wikipedia.pt\n",
      "$ (cwd=/Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/explainer/tempme) python /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/submodules/explainer/tempme/temp_exp_main.py --base_type tgn --data wikipedia\n",
      "[TempME][warn] train length mismatch (data=79376, pack=78328, edge=78328); truncating to 78328.\n",
      "num of training instances: 78327\n",
      "num of batches per epoch: 157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [14:42<00:00,  5.62s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 0 | Training loss: 0.6273002719423574 | Training Aps: 0.8190886825868646 | Training Auc: 0.8390720755499802 | Training Acc: 0.7649673223495483 | Training Fidelity Prob: -0.06546329799446331 | Training Fidelity Logit: -0.5630680062588612 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [24:17<00:00, 31.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Epoch: 0 | Testing loss: 1.9395083468011085 | Testing Aps: 0.7653917566874688 | Testing Auc: 0.7684823910856019 | Testing Acc: 0.7084042429924011 | Testing Fidelity Prob: -0.07270217663113107 | Testing Fidelity Logit: -0.8802369243287026 | Ratio APS: 0.8405448948145849 | Ratio AUC: 0.8441860781428425 | Ratio ACC: 0.7730239629745483 | Ratio Prob: -0.044905557074247204 | Ratio Logit: -0.586092518444391 | \n",
      "Save model to /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/explainer/tempme/params/explainer/tgn/wikipedia.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [21:08<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1 | Training loss: 0.617304462156478 | Training Aps: 0.8232779715244724 | Training Auc: 0.8422374019915354 | Training Acc: 0.7667992115020752 | Training Fidelity Prob: -0.06284938617401821 | Training Fidelity Logit: -0.520791995107748 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [29:15<00:00, 37.34s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Epoch: 1 | Testing loss: 1.9560121209063428 | Testing Aps: 0.7666754909930427 | Testing Auc: 0.7685553404926309 | Testing Acc: 0.7084254622459412 | Testing Fidelity Prob: -0.07246025120641322 | Testing Fidelity Logit: -0.8866333435190484 | Ratio APS: 0.8405520930181684 | Ratio AUC: 0.8441681083225185 | Ratio ACC: 0.7729122042655945 | Ratio Prob: -0.04468931466900803 | Ratio Logit: -0.5884482634273616 | \n",
      "Save model to /Users/juliawenkmann/Documents/CodingProjects/master_thesis/time_to_explain/resources/explainer/tempme/params/explainer/tgn/wikipedia.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [28:13<00:00, 10.79s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 2 | Training loss: 0.613056160082483 | Training Aps: 0.8214146361191836 | Training Auc: 0.8415887051470569 | Training Acc: 0.7681507468223572 | Training Fidelity Prob: -0.06409916960319896 | Training Fidelity Logit: -0.5265381249367811 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [49:07<00:00, 62.71s/it]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Epoch: 2 | Testing loss: 2.0021437609449344 | Testing Aps: 0.7683832499973758 | Testing Auc: 0.7693736418691703 | Testing Acc: 0.7098512053489685 | Testing Fidelity Prob: -0.07033867476151344 | Testing Fidelity Logit: -0.9171972769372007 | Ratio APS: 0.8394373653830243 | Ratio AUC: 0.8434506601323264 | Ratio ACC: 0.7727606892585754 | Ratio Prob: -0.04485429539729128 | Ratio Logit: -0.5909162683095387 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [22:34<00:00,  8.63s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 3 | Training loss: 0.6190024889578485 | Training Aps: 0.8189980131484723 | Training Auc: 0.8398551366883461 | Training Acc: 0.7661176323890686 | Training Fidelity Prob: -0.06458477820655342 | Training Fidelity Logit: -0.5272980766121749 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [26:18<00:00, 33.59s/it]\n",
      "  0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Epoch: 3 | Testing loss: 2.0037016361317734 | Testing Aps: 0.7648606565794329 | Testing Auc: 0.7661414310759391 | Testing Acc: 0.7071064114570618 | Testing Fidelity Prob: -0.07377221268859316 | Testing Fidelity Logit: -0.9141162798759785 | Ratio APS: 0.8388455200821321 | Ratio AUC: 0.8427884385348522 | Ratio ACC: 0.7715041041374207 | Ratio Prob: -0.04477435637802936 | Ratio Logit: -0.5865959193993439 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 157/157 [22:06<00:00,  8.45s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 4 | Training loss: 0.6121558100934241 | Training Aps: 0.8197334132102199 | Training Auc: 0.8408338952365195 | Training Acc: 0.767620861530304 | Training Fidelity Prob: -0.06460123986100695 | Training Fidelity Logit: -0.5404850219845012 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 30/47 [1:09:19<39:07, 138.09s/it]/Users/juliawenkmann/miniconda3/envs/graphs/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 87\u001b[0m\n\u001b[1;32m     85\u001b[0m expl_args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: TEMP_ME_BASE_TYPE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mTEMP_ME_EXP_OVERRIDES}\n\u001b[1;32m     86\u001b[0m cmd \u001b[38;5;241m=\u001b[39m build_cmd(PYTHON_BIN, TEMP_ME_EXP_MAIN, args_dict_to_list(expl_args, dataset))\n\u001b[0;32m---> 87\u001b[0m code \u001b[38;5;241m=\u001b[39m run_cmd(cmd, env\u001b[38;5;241m=\u001b[39menv, workdir\u001b[38;5;241m=\u001b[39mTEMP_ME_ROOT, dry_run\u001b[38;5;241m=\u001b[39mDRY_RUN)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTempME explainer training failed; see logs above.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/CodingProjects/master_thesis/time_to_explain/time_to_explain/models/utils.py:46\u001b[0m, in \u001b[0;36mrun_cmd\u001b[0;34m(cmd, env, workdir, dry_run)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DRY_RUN] Skipping execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 46\u001b[0m proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd_list, env\u001b[38;5;241m=\u001b[39menv, cwd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(workdir), check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ERROR] process exited with code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproc\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/graphs/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/graphs/lib/python3.11/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphs/lib/python3.11/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphs/lib/python3.11/subprocess.py:2051\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2051\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_wait(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2052\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2053\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/envs/graphs/lib/python3.11/subprocess.py:2009\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2009\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwaitpid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid, wait_flags)\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2011\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2012\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2013\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- TempME pretraining (base model + explainer) ---\n",
    "# Runs in a clean process to avoid memory pressure during evaluation.\n",
    "TEMP_ME_BASE_TYPE = MODEL_TYPE.lower()\n",
    "if TEMP_ME_BASE_TYPE not in {\"tgn\", \"tgat\", \"graphmixer\"}:\n",
    "    TEMP_ME_BASE_TYPE = \"tgn\"\n",
    "\n",
    "TEMP_ME_ROOT = PROJECT_ROOT / \"submodules\" / \"explainer\" / \"tempme\"\n",
    "TEMP_ME_LEARN_BASE = TEMP_ME_ROOT / \"learn_base.py\"\n",
    "TEMP_ME_EXP_MAIN = TEMP_ME_ROOT / \"temp_exp_main.py\"\n",
    "\n",
    "TEMP_ME_CKPT_ROOT = PROJECT_ROOT / \"resources\" / \"explainer\" / \"tempme\"\n",
    "\n",
    "LEGACY_TEMP_ME_CKPT_ROOT = TEMP_ME_ROOT / \"params\"\n",
    "\n",
    "# Optional overrides to reduce memory usage. Leave empty to use TempME defaults.\n",
    "TEMP_ME_BASE_OVERRIDES = {\n",
    "    # \"bs\": 128,\n",
    "    # \"n_epoch\": 50,\n",
    "}\n",
    "TEMP_ME_EXP_OVERRIDES = {\n",
    "    # \"bs\": 128,\n",
    "    # \"test_bs\": 128,\n",
    "    # \"n_epoch\": 80,\n",
    "}\n",
    "\n",
    "from time_to_explain.data.tgnn_setup import setup_tgnn_data\n",
    "import shutil\n",
    "\n",
    "REAL_TGNN_DATASETS = {\"wikipedia\", \"reddit\", \"simulate_v1\", \"simulate_v2\", \"multihost\"}\n",
    "\n",
    "def _ensure_tempme_inputs(dataset: str) -> None:\n",
    "    missing = []\n",
    "    for fname in (f\"ml_{dataset}.csv\", f\"ml_{dataset}.npy\", f\"ml_{dataset}_node.npy\"):\n",
    "        if not (RESOURCES_DATASETS / fname).exists():\n",
    "            missing.append(fname)\n",
    "    if not missing:\n",
    "        return\n",
    "    print(\"[TempME] Missing processed files, regenerating:\", \", \".join(missing))\n",
    "    if dataset not in REAL_TGNN_DATASETS:\n",
    "        raise ValueError(f\"TempME inputs missing for '{dataset}'. Prepare the dataset or add it to REAL_TGNN_DATASETS.\")\n",
    "    setup_tgnn_data(root=PROJECT_ROOT, only=[dataset], force=False, do_process=True)\n",
    "\n",
    "def _copy_if_missing(src: Path, dst: Path) -> None:\n",
    "    if not src.exists() or dst.exists():\n",
    "        return\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        dst.symlink_to(src)\n",
    "    except Exception:\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "def _maybe_migrate_tempme_ckpts(base_type: str, dataset: str) -> None:\n",
    "    legacy_base = LEGACY_TEMP_ME_CKPT_ROOT / \"tgnn\" / f\"{base_type}_{dataset}.pt\"\n",
    "    legacy_expl = LEGACY_TEMP_ME_CKPT_ROOT / \"explainer\" / base_type / f\"{dataset}.pt\"\n",
    "    new_base, new_expl = _tempme_ckpts(base_type, dataset)\n",
    "    _copy_if_missing(legacy_base, new_base)\n",
    "    _copy_if_missing(legacy_expl, new_expl)\n",
    "\n",
    "def _tempme_ckpts(base_type: str, dataset: str):\n",
    "    base_ckpt = TEMP_ME_CKPT_ROOT / \"params\" / \"tgnn\" / f\"{base_type}_{dataset}.pt\"\n",
    "    expl_ckpt = TEMP_ME_CKPT_ROOT / \"params\" / \"explainer\" / base_type / f\"{dataset}.pt\"\n",
    "    return base_ckpt, expl_ckpt\n",
    "\n",
    "env = prepare_env(project_root=PROJECT_ROOT, cuda_visible_devices=CUDA_VISIBLE_DEVICES)\n",
    "\n",
    "for dataset in DATASET_LIST:\n",
    "    _maybe_migrate_tempme_ckpts(TEMP_ME_BASE_TYPE, dataset)\n",
    "\n",
    "    _ensure_tempme_inputs(dataset)\n",
    "\n",
    "    base_ckpt, expl_ckpt = _tempme_ckpts(TEMP_ME_BASE_TYPE, dataset)\n",
    "\n",
    "    if base_ckpt.exists():\n",
    "        print(\"[TempME] Base checkpoint exists:\", base_ckpt)\n",
    "    else:\n",
    "        base_args = {\"base_type\": TEMP_ME_BASE_TYPE, \"data\": dataset, **TEMP_ME_BASE_OVERRIDES}\n",
    "        cmd = build_cmd(PYTHON_BIN, TEMP_ME_LEARN_BASE, args_dict_to_list(base_args, dataset))\n",
    "        code = run_cmd(cmd, env=env, workdir=TEMP_ME_ROOT, dry_run=DRY_RUN)\n",
    "        if code != 0:\n",
    "            raise RuntimeError(\"TempME base training failed; see logs above.\")\n",
    "\n",
    "    if expl_ckpt.exists():\n",
    "        print(\"[TempME] Explainer checkpoint exists:\", expl_ckpt)\n",
    "    else:\n",
    "        expl_args = {\"base_type\": TEMP_ME_BASE_TYPE, \"data\": dataset, **TEMP_ME_EXP_OVERRIDES}\n",
    "        cmd = build_cmd(PYTHON_BIN, TEMP_ME_EXP_MAIN, args_dict_to_list(expl_args, dataset))\n",
    "        code = run_cmd(cmd, env=env, workdir=TEMP_ME_ROOT, dry_run=DRY_RUN)\n",
    "        if code != 0:\n",
    "            raise RuntimeError(\"TempME explainer training failed; see logs above.\")\n",
    "\n",
    "    print(\"[TempME] Ready for dataset:\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact-edge check device: cpu\n",
      "Skip wikipedia: contact-edge check is configured for stick_figure/sticky_hips only.\n"
     ]
    }
   ],
   "source": [
    "# --- Contact edge sanity check + visualization (stick_figure + sticky_hips + TGN) ---\n",
    "if DRY_RUN:\n",
    "    print(\"Skip contact-edge check (DRY_RUN=True).\")\n",
    "elif MODEL_TYPE.upper() != \"TGN\":\n",
    "    print(\"Skip contact-edge check (MODEL_TYPE != TGN).\")\n",
    "else:\n",
    "    import json\n",
    "    import math\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import torch\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    from time_to_explain.data.synthetic_recipes.stick_figure import JOINTS_PER_PERSON\n",
    "    from time_to_explain.visualization.utils import COLORS\n",
    "    from submodules.models.tgn.model.tgn import TGN\n",
    "    from submodules.models.tgn.tgn_utils.data_processing import get_data, compute_time_statistics\n",
    "    from submodules.models.tgn.tgn_utils.utils import RandEdgeSampler, get_neighbor_finder\n",
    "\n",
    "    def _find_checkpoint(models_root: Path, dataset_name: str, model_name: str) -> Path:\n",
    "        model_name = model_name.lower()\n",
    "        dataset_name = str(dataset_name)\n",
    "        candidates = [\n",
    "            models_root / dataset_name / model_name / f\"{model_name}_{dataset_name}_best.pth\",\n",
    "            models_root / dataset_name / \"checkpoints\" / f\"{model_name}_{dataset_name}_best.pth\",\n",
    "            models_root / \"checkpoints\" / f\"{model_name}_{dataset_name}_best.pth\",\n",
    "        ]\n",
    "        for cand in candidates:\n",
    "            if cand.exists():\n",
    "                return cand\n",
    "        search_roots = [\n",
    "            models_root / dataset_name / model_name,\n",
    "            models_root / dataset_name,\n",
    "            models_root / \"checkpoints\",\n",
    "        ]\n",
    "        for root in search_roots:\n",
    "            if not root.exists():\n",
    "                continue\n",
    "            matches = sorted(root.rglob(f\"{model_name}*{dataset_name}*.pth\"))\n",
    "            if not matches:\n",
    "                matches = sorted(root.rglob(\"*.pth\"))\n",
    "            for match in matches:\n",
    "                if \"best\" in match.name:\n",
    "                    return match\n",
    "            if matches:\n",
    "                return matches[0]\n",
    "        raise FileNotFoundError(\n",
    "            f\"Checkpoint not found under {models_root} for {model_name}_{dataset_name}.\"\n",
    "        )\n",
    "\n",
    "    def _build_tgn_args(train_args: dict) -> dict:\n",
    "        return {\n",
    "            \"n_layers\": int(train_args.get(\"n_layer\", train_args.get(\"n_layers\", 1))),\n",
    "            \"n_heads\": int(train_args.get(\"n_head\", train_args.get(\"n_heads\", 2))),\n",
    "            \"dropout\": float(train_args.get(\"drop_out\", 0.1)),\n",
    "            \"use_memory\": bool(train_args.get(\"use_memory\", False)),\n",
    "            \"message_dimension\": int(train_args.get(\"message_dim\", 100)),\n",
    "            \"memory_dimension\": int(train_args.get(\"memory_dim\", 172)),\n",
    "            \"memory_update_at_start\": not bool(train_args.get(\"memory_update_at_end\", False)),\n",
    "            \"embedding_module_type\": str(train_args.get(\"embedding_module\", \"graph_attention\")),\n",
    "            \"message_function\": str(train_args.get(\"message_function\", \"identity\")),\n",
    "            \"aggregator_type\": str(train_args.get(\"aggregator\", \"last\")),\n",
    "            \"memory_updater_type\": str(train_args.get(\"memory_updater\", \"gru\")),\n",
    "            \"use_destination_embedding_in_message\": bool(train_args.get(\"use_destination_embedding_in_message\", False)),\n",
    "            \"use_source_embedding_in_message\": bool(train_args.get(\"use_source_embedding_in_message\", False)),\n",
    "            \"dyrep\": bool(train_args.get(\"dyrep\", False)),\n",
    "        }\n",
    "\n",
    "    def _load_processed_tables(dataset: str) -> tuple[pd.DataFrame, np.ndarray, dict]:\n",
    "        flat_csv = RESOURCES_DATASETS / f\"ml_{dataset}.csv\"\n",
    "        if flat_csv.exists():\n",
    "            data_dir = RESOURCES_DATASETS\n",
    "        else:\n",
    "            data_dir = RESOURCES_DATASETS / dataset\n",
    "        graph_df = pd.read_csv(data_dir / f\"ml_{dataset}.csv\")\n",
    "        edge_features = np.load(data_dir / f\"ml_{dataset}.npy\")\n",
    "        meta_path = data_dir / f\"ml_{dataset}.json\"\n",
    "        meta = json.loads(meta_path.read_text(encoding=\"utf-8\")) if meta_path.exists() else {}\n",
    "        return graph_df, edge_features, meta\n",
    "\n",
    "\n",
    "    def _plot_frame(\n",
    "        frame_id: int,\n",
    "        *,\n",
    "        title: str,\n",
    "        probs: dict | None = None,\n",
    "        show_gt: bool = True,\n",
    "        pred_query_only: bool = True,\n",
    "    ) -> go.Figure:\n",
    "        fig = go.Figure()\n",
    "        mask = (clip_ids == clip_id) & (frame_idx == frame_id)\n",
    "        indices = np.where(mask)[0]\n",
    "\n",
    "        if show_gt and probs is not None:\n",
    "            for idx in indices:\n",
    "                if is_query[idx]:\n",
    "                    continue\n",
    "                coords = feat_map[idx]\n",
    "                x0, y0, x1, y1 = [float(v) for v in coords[:4]]\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[x0, x1],\n",
    "                        y=[y0, y1],\n",
    "                        mode=\"lines\",\n",
    "                        line=dict(color=COLORS[\"base\"], width=1.2),\n",
    "                        opacity=0.35,\n",
    "                        hoverinfo=\"skip\",\n",
    "                        showlegend=False,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        for idx in indices:\n",
    "            coords = feat_map[idx]\n",
    "            x0, y0, x1, y1 = [float(v) for v in coords[:4]]\n",
    "            if probs is None:\n",
    "                if is_query[idx]:\n",
    "                    color = COLORS[\"accent\"]\n",
    "                    width = 3.2\n",
    "                else:\n",
    "                    color = COLORS[\"base\"]\n",
    "                    width = 2.0\n",
    "            else:\n",
    "                if pred_query_only and not is_query[idx]:\n",
    "                    continue\n",
    "                prob = probs.get(int(idx), 0.0)\n",
    "                if prob < 0.5:\n",
    "                    continue\n",
    "                color = COLORS[\"user\"]\n",
    "                width = 2.8\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[x0, x1],\n",
    "                    y=[y0, y1],\n",
    "                    mode=\"lines\",\n",
    "                    line=dict(color=color, width=width),\n",
    "                    hovertemplate=f\"edge_idx={idx_vals[idx]}<extra></extra>\",\n",
    "                    showlegend=False,\n",
    "                )\n",
    "            )\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            template=\"simple_white\",\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False, scaleanchor=\"x\", scaleratio=1),\n",
    "            margin=dict(l=20, r=20, t=60, b=20),\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    tgn_spec = MODEL_SPECS.get(\"TGN\", {})\n",
    "    train_args = dict(tgn_spec.get(\"args\") or {})\n",
    "    n_neighbors = int(train_args.get(\"n_degree\", 10))\n",
    "    batch_size = int(train_args.get(\"bs\", 200))\n",
    "    tgn_args = _build_tgn_args(train_args)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Contact-edge check device:\", device)\n",
    "\n",
    "    for dataset in DATASET_LIST:\n",
    "        if dataset not in {\"stick_figure\", \"sticky_hips\"}:\n",
    "            print(f\"Skip {dataset}: contact-edge check is configured for stick_figure/sticky_hips only.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            ckpt_path = _find_checkpoint(RESOURCES_MODELS, dataset, \"tgn\")\n",
    "        except FileNotFoundError as exc:\n",
    "            print(f\"Skip {dataset}: {exc}\")\n",
    "            continue\n",
    "        print(\"Using checkpoint:\", ckpt_path)\n",
    "\n",
    "        node_features, edge_features, full_data, _train_data, _val_data, test_data, _nn_val, _nn_test = get_data(dataset)\n",
    "        m_src, s_src, m_dst, s_dst = compute_time_statistics(\n",
    "            full_data.sources, full_data.destinations, full_data.timestamps\n",
    "        )\n",
    "        full_ngh_finder = get_neighbor_finder(full_data, uniform=False)\n",
    "\n",
    "        model = TGN(\n",
    "            neighbor_finder=full_ngh_finder,\n",
    "            node_features=node_features,\n",
    "            edge_features=edge_features,\n",
    "            device=device,\n",
    "            n_neighbors=n_neighbors,\n",
    "            mean_time_shift_src=m_src,\n",
    "            std_time_shift_src=s_src,\n",
    "            mean_time_shift_dst=m_dst,\n",
    "            std_time_shift_dst=s_dst,\n",
    "            **tgn_args,\n",
    "        )\n",
    "        state_dict = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "        filtered_state = {\n",
    "            k: v\n",
    "            for k, v in state_dict.items()\n",
    "            if not (k.startswith(\"memory.\") or k.startswith(\"memory_updater.memory.\"))\n",
    "        }\n",
    "        _ = model.load_state_dict(filtered_state, strict=False)\n",
    "        model = model.to(device).eval()\n",
    "        if getattr(model, \"use_memory\", False) and getattr(model, \"memory\", None) is not None:\n",
    "            model.memory.__init_memory__()\n",
    "\n",
    "        graph_df, edge_feat_full, meta = _load_processed_tables(dataset)\n",
    "        cfg_meta = meta.get(\"config\") if isinstance(meta.get(\"config\"), dict) else {}\n",
    "        frames = int(cfg_meta.get(\"frames\", 30))\n",
    "\n",
    "        idx_col = \"idx\" if \"idx\" in graph_df.columns else (\"e_idx\" if \"e_idx\" in graph_df.columns else None)\n",
    "        if idx_col is None:\n",
    "            print(\"Paired contact check skipped: missing idx/e_idx.\")\n",
    "            continue\n",
    "        idx_vals = graph_df[idx_col].astype(int).to_numpy()\n",
    "        if edge_feat_full.ndim != 2 or edge_feat_full.shape[1] < 9:\n",
    "            print(\"Paired contact check skipped: edge_features missing frame info.\")\n",
    "            continue\n",
    "        if edge_feat_full.shape[0] > int(idx_vals.max()):\n",
    "            feat_map = edge_feat_full[idx_vals]\n",
    "        elif edge_feat_full.shape[0] == len(graph_df):\n",
    "            feat_map = edge_feat_full\n",
    "        else:\n",
    "            print(\"Paired contact check skipped: edge_features length mismatch.\")\n",
    "            continue\n",
    "\n",
    "        u_all = graph_df[\"u\"].astype(int).to_numpy()\n",
    "        v_all = graph_df[\"i\"].astype(int).to_numpy()\n",
    "        ts_all = graph_df[\"ts\"].astype(float).to_numpy()\n",
    "        frame_norm = feat_map[:, 8]\n",
    "        is_query = feat_map[:, 7] >= 0.5\n",
    "\n",
    "        node_min = int(min(u_all.min(), v_all.min()))\n",
    "        node_base = 1 if node_min >= 1 else 0\n",
    "        clip_ids = (u_all - node_base) // JOINTS_PER_PERSON\n",
    "        num_clips = int(clip_ids.max() + 1)\n",
    "        frame_idx = np.clip(np.rint(frame_norm * (frames - 1)), 0, frames - 1).astype(int)\n",
    "\n",
    "        frame_time = np.full((num_clips, frames), np.nan)\n",
    "        contact_present = np.zeros((num_clips, frames), dtype=bool)\n",
    "        for i in range(len(graph_df)):\n",
    "            c = int(clip_ids[i])\n",
    "            f = int(frame_idx[i])\n",
    "            if is_query[i]:\n",
    "                contact_present[c, f] = True\n",
    "            if np.isnan(frame_time[c, f]) or ts_all[i] < frame_time[c, f]:\n",
    "                frame_time[c, f] = ts_all[i]\n",
    "\n",
    "        idx_to_row = {int(v): i for i, v in enumerate(idx_vals.tolist())}\n",
    "        pos_mask = np.asarray(test_data.labels) == 1\n",
    "        pos_edge_idxs = np.asarray(test_data.edge_idxs)[pos_mask]\n",
    "\n",
    "        pos_sources = []\n",
    "        pos_destinations = []\n",
    "        pos_times = []\n",
    "        neg_sources = []\n",
    "        neg_destinations = []\n",
    "        neg_times = []\n",
    "\n",
    "        def _find_non_contact_frame(c: int, f: int) -> int | None:\n",
    "            for delta in range(1, frames):\n",
    "                lo = f - delta\n",
    "                hi = f + delta\n",
    "                if lo >= 0 and not contact_present[c, lo] and not np.isnan(frame_time[c, lo]):\n",
    "                    return lo\n",
    "                if hi < frames and not contact_present[c, hi] and not np.isnan(frame_time[c, hi]):\n",
    "                    return hi\n",
    "            return None\n",
    "\n",
    "        for e_idx in pos_edge_idxs:\n",
    "            row_idx = idx_to_row.get(int(e_idx))\n",
    "            if row_idx is None or not is_query[row_idx]:\n",
    "                continue\n",
    "            c = int(clip_ids[row_idx])\n",
    "            f = int(frame_idx[row_idx])\n",
    "            neg_f = _find_non_contact_frame(c, f)\n",
    "            if neg_f is None:\n",
    "                continue\n",
    "            pos_sources.append(int(u_all[row_idx]))\n",
    "            pos_destinations.append(int(v_all[row_idx]))\n",
    "            pos_times.append(float(ts_all[row_idx]))\n",
    "            neg_sources.append(int(u_all[row_idx]))\n",
    "            neg_destinations.append(int(v_all[row_idx]))\n",
    "            neg_times.append(float(frame_time[c, neg_f]))\n",
    "\n",
    "        if not pos_sources:\n",
    "            print(\"Paired contact check: no usable contact/non-contact pairs found.\")\n",
    "            continue\n",
    "\n",
    "        pos_sources = np.asarray(pos_sources)\n",
    "        pos_destinations = np.asarray(pos_destinations)\n",
    "        pos_times = np.asarray(pos_times)\n",
    "        neg_sources = np.asarray(neg_sources)\n",
    "        neg_destinations = np.asarray(neg_destinations)\n",
    "        neg_times = np.asarray(neg_times)\n",
    "\n",
    "        sampler = RandEdgeSampler(full_data.sources, full_data.destinations, seed=0)\n",
    "\n",
    "        prev_forbidden = getattr(model, \"forbidden_memory_update\", False)\n",
    "        model.forbidden_memory_update = True\n",
    "        if getattr(model, \"use_memory\", False) and getattr(model, \"memory\", None) is not None:\n",
    "            model.memory.__init_memory__()\n",
    "\n",
    "        def _batched_pos_probs(src: np.ndarray, dst: np.ndarray, ts: np.ndarray) -> np.ndarray:\n",
    "            out = []\n",
    "            n = len(src)\n",
    "            for i in range(0, n, batch_size):\n",
    "                s = src[i:i + batch_size]\n",
    "                d = dst[i:i + batch_size]\n",
    "                t = ts[i:i + batch_size]\n",
    "                if len(s) == 0:\n",
    "                    continue\n",
    "                _, neg = sampler.sample(len(s))\n",
    "                edge_idx_dummy = np.zeros(len(s), dtype=int)\n",
    "                pos_prob, _ = model.compute_edge_probabilities(\n",
    "                    s,\n",
    "                    d,\n",
    "                    neg,\n",
    "                    t,\n",
    "                    edge_idx_dummy,\n",
    "                    n_neighbors=n_neighbors,\n",
    "                )\n",
    "                out.append(pos_prob.detach().cpu().numpy())\n",
    "            return np.concatenate(out) if out else np.array([])\n",
    "\n",
    "        pos_prob_pair = _batched_pos_probs(pos_sources, pos_destinations, pos_times)\n",
    "        neg_prob_pair = _batched_pos_probs(neg_sources, neg_destinations, neg_times)\n",
    "\n",
    "        model.forbidden_memory_update = prev_forbidden\n",
    "\n",
    "        pos_hit = int(np.sum(pos_prob_pair >= 0.5))\n",
    "        neg_reject = int(np.sum(neg_prob_pair < 0.5))\n",
    "        total = int(pos_prob_pair.size)\n",
    "        print(f\"Paired contact hit-rate (pos >= 0.5): {100.0 * pos_hit / total:.2f}% ({pos_hit}/{total})\")\n",
    "        print(f\"Paired non-contact reject (neg < 0.5): {100.0 * neg_reject / total:.2f}% ({neg_reject}/{total})\")\n",
    "\n",
    "        # Visualization: predictions at multiple frames\n",
    "        row_idx = None\n",
    "        for e_idx in pos_edge_idxs:\n",
    "            idx = idx_to_row.get(int(e_idx))\n",
    "            if idx is not None and is_query[idx]:\n",
    "                row_idx = idx\n",
    "                break\n",
    "        if row_idx is None:\n",
    "            print(\"Visualization skipped: no contact edge found in test split.\")\n",
    "            continue\n",
    "\n",
    "        clip_id = int(clip_ids[row_idx])\n",
    "        frame_contact = int(frame_idx[row_idx])\n",
    "        pred_frames = 8\n",
    "        start_frame = max(0, frame_contact - (pred_frames // 2))\n",
    "        end_frame = min(frames - 1, start_frame + pred_frames - 1)\n",
    "        start_frame = max(0, end_frame - (pred_frames - 1))\n",
    "        display_frames = list(range(start_frame, end_frame + 1))\n",
    "\n",
    "        prev_forbidden = getattr(model, \"forbidden_memory_update\", False)\n",
    "        model.forbidden_memory_update = False\n",
    "        if getattr(model, \"use_memory\", False) and getattr(model, \"memory\", None) is not None:\n",
    "            model.memory.__init_memory__()\n",
    "\n",
    "        frame_probs: dict[int, dict[int, float]] = {}\n",
    "        for f in range(frames):\n",
    "            indices_f = np.where((clip_ids == clip_id) & (frame_idx == f))[0]\n",
    "            if len(indices_f) == 0:\n",
    "                continue\n",
    "            s = u_all[indices_f]\n",
    "            d = v_all[indices_f]\n",
    "            t = ts_all[indices_f]\n",
    "            e = idx_vals[indices_f]\n",
    "            _, neg = sampler.sample(len(s))\n",
    "            pos_prob, _ = model.compute_edge_probabilities(\n",
    "                s,\n",
    "                d,\n",
    "                neg,\n",
    "                t,\n",
    "                e,\n",
    "                n_neighbors=n_neighbors,\n",
    "            )\n",
    "            if f in display_frames:\n",
    "                probs = {\n",
    "                    int(idx): float(p)\n",
    "                    for idx, p in zip(indices_f, pos_prob.detach().cpu().numpy())\n",
    "                }\n",
    "                frame_probs[int(f)] = probs\n",
    "\n",
    "        model.forbidden_memory_update = prev_forbidden\n",
    "\n",
    "        if not frame_probs:\n",
    "            print(\"Visualization skipped: no frames selected.\")\n",
    "            continue\n",
    "\n",
    "        for f in display_frames:\n",
    "            probs = frame_probs.get(int(f))\n",
    "            if not probs:\n",
    "                continue\n",
    "            contact_flag = \"contact\" if contact_present[clip_id, f] else \"no contact\"\n",
    "            fig_pred = _plot_frame(\n",
    "                f,\n",
    "                title=f\"{dataset}: predictions at frame {f} ({contact_flag})\",\n",
    "                probs=probs,\n",
    "                show_gt=True,\n",
    "                pred_query_only=True,\n",
    "            )\n",
    "            fig_pred.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}