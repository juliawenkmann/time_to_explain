import argparse
import json
import logging
import os.path
import time
from pathlib import Path
from typing import List

import numpy as np
import pandas as pd

from cody.data import TrainTestDatasetParameters
from cody.embedding import StaticEmbedding
from cody.utils import ProgressBar

from common import add_dataset_arguments, add_wrapper_model_arguments, create_dataset_from_args, parse_args, \
    get_event_ids_from_file, column_to_int_array, column_to_float_array, create_ttgnn_wrapper_from_args

from cody.explainer.baseline.pgexplainer import TPGExplainer, FactualExplanation
from cody.explainer.baseline.tgnnexplainer import TGNNExplainer, TGNNExplainerExplanation

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger()


def evaluate(evaluated_explainer: TGNNExplainer | TPGExplainer, explained_event_ids: np.ndarray,
             max_time_seconds: int = 72 * 60):
    explanation_list = []

    progress_bar = ProgressBar(len(explained_event_ids), prefix='Evaluating explainer')
    start_time = time.time()

    for event_id in explained_event_ids:
        if time.time() - start_time > max_time_seconds:
            logger.info("Time limit reached. Finishing evaluation...")
            break
        progress_bar.update_postfix(f'Generating explanation for event {event_id}')
        try:
            explanation = evaluated_explainer.explain(event_id)
            sparsity_list, fidelity_list, fidelity_best = evaluated_explainer.evaluate_fidelity(explanation)
            explanation.statistics['sparsity'] = sparsity_list
            explanation.statistics['fidelity'] = fidelity_list
            explanation.statistics['best fidelity'] = fidelity_best
            explanation_list.append(explanation)
        except RuntimeError:
            progress_bar.write(f'Could not find any candidates to explain {event_id}')
        progress_bar.next()
    progress_bar.close()
    return explanation_list


def export_explanations(explanation_list: List[FactualExplanation | TGNNExplainerExplanation], filepath: str):
    explanations_dicts = [explanation.to_dict() for explanation in explanation_list]
    explanations_df = pd.DataFrame(explanations_dicts)
    parquet_file_path = filepath.rstrip('csv') + 'parquet'
    if os.path.exists(parquet_file_path):
        existing_results = pd.read_parquet(parquet_file_path)
        explanations_df = pd.concat([existing_results, explanations_df], axis='rows')
    elif os.path.exists(filepath):
        existing_results = pd.read_csv(filepath)
        existing_results = existing_results.iloc[:, 1:]
        existing_results['results'] = existing_results['results'].str.replace("\'", '\"')
        existing_results['results'] = existing_results['results'].apply(lambda x: json.loads(x))
        column_to_int_array(existing_results, 'candidates')
        column_to_float_array(existing_results, 'sparsity')
        column_to_float_array(existing_results, 'fidelity')
        column_to_float_array(existing_results, 'best fidelity')
        explanations_df = pd.concat([existing_results, explanations_df], axis='rows')
    try:
        explanations_df.to_parquet(filepath.rstrip('csv') + 'parquet')
        logger.info(f'Saved evaluation results to {parquet_file_path}')
    except ImportError:
        logger.info('Failed to export to parquet format. Install pyarrow to export to parquet format '
                    '(pip install pyarrow)')
    explanations_df.to_csv(filepath)
    logger.info(f'Saved evaluation results to {filepath}')


if __name__ == '__main__':
    parser = argparse.ArgumentParser('Factual Explainer Evaluation')
    add_dataset_arguments(parser)
    add_wrapper_model_arguments(parser)
    parser.add_argument('--explained_ids', required=True, type=str,
                        help='Path to the file containing all the event ids that should be explained')
    parser.add_argument('--wrong_predictions_only', action='store_true',
                        help='Provide if evaluation should focus on wrong predictions only')
    parser.add_argument('-r', '--results', required=True, type=str,
                        help='Filepath for the evaluation results')
    parser.add_argument('--explainer', required=True, type=str, help='Which explainer to evaluate',
                        choices=['pg_explainer', 't_gnnexplainer'])
    parser.add_argument('--explainer_model_path', type=str, required=True,
                        help='Path to the model file of the PG-Explainer model')
    parser.add_argument('--rollout', type=int, default=500,
                        help='Number of rollouts to perform in the MCTS')
    parser.add_argument('--mcts_save_dir', type=str, required=True,
                        help='Path to which the results of the mcts are written to')
    parser.add_argument('--number_of_explained_events', type=int, default=1000,
                        help='Number of event ids to explain. Only has an effect if the explained_ids file has not '
                             'been initialized yet')
    parser.add_argument('--max_time', type=int, default=2400,
                        help='Maximal runtime (minutes)')

    args = parse_args(parser)

    dataset = create_dataset_from_args(args, TrainTestDatasetParameters(0.2, 0.6, 0.8, args.number_of_explained_events,
                                                                        500, 500))

    tgn_wrapper = create_ttgnn_wrapper_from_args(args, dataset)

    event_ids_to_explain = get_event_ids_from_file(args.explained_ids, logger, args.wrong_predictions_only,
                                                   tgn_wrapper)

    embedding = StaticEmbedding(dataset, tgn_wrapper)

    pg_explainer = TPGExplainer(tgn_wrapper, embedding=embedding, device=tgn_wrapper.device)

    match args.explainer:
        case 'pg_explainer':
            explainer = pg_explainer
        case 't_gnnexplainer':
            explainer = TGNNExplainer(tgn_wrapper, embedding, pg_explainer, results_dir=args.mcts_save_dir,
                                      device=tgn_wrapper.device, rollout=args.rollout, mcts_saved_dir=None,
                                      save_results=True)
        case _:
            raise NotImplementedError

    if os.path.exists(args.results):
        previous_results = pd.read_csv(args.results)
        encountered_event_ids = previous_results['explained_event_id'].to_numpy()
        logger.info(f'Resuming evaluation. '
                    f'Already processed {len(encountered_event_ids)}/{len(event_ids_to_explain)} events.')
        event_ids_to_explain = event_ids_to_explain[~np.isin(event_ids_to_explain, encountered_event_ids)]
    else:
        Path(args.results).parent.mkdir(parents=True, exist_ok=True)

    explanations = evaluate(explainer, event_ids_to_explain, args.max_time * 60)
    export_explanations(explanations, args.results)
